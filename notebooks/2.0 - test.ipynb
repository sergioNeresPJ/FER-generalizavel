{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.4.1+cu121\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"ZE_ENABLE_TRACING_LAYER\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importar simple tokenizer.py, model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1736782222337,
     "user": {
      "displayName": "Sergio Neres Pereira Junior",
      "userId": "05770949936273593301"
     },
     "user_tz": 180
    },
    "id": "KbEsq3Rw0zdc"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Obtém o caminho absoluto para o diretório 'src'\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
    "\n",
    "# Adiciona o diretório 'src' ao sys.path\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "# Agora você pode importar módulos de dentro de 'src' como se fosse um pacote de nível superior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 425,
     "status": "ok",
     "timestamp": 1736782259432,
     "user": {
      "displayName": "Sergio Neres Pereira Junior",
      "userId": "05770949936273593301"
     },
     "user_tz": 180
    },
    "id": "8zH1mnyP_qbW"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--raf_path', type=str, default='../../data/raf-basic', help='raf_dataset_path')\n",
    "parser.add_argument('--resnet50_path', type=str, default='../../data/resnet50_ft_weight.pkl', help='pretrained_backbone_path')\n",
    "parser.add_argument('--label_path', type=str, default='list_patition_label.txt', help='label_path')\n",
    "parser.add_argument('--workers', type=int, default=2, help='number of workers')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='batch_size')\n",
    "parser.add_argument('--w', type=int, default=7, help='width of the attention map')\n",
    "parser.add_argument('--h', type=int, default=7, help='height of the attention map')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='the number of the device')\n",
    "parser.add_argument('--lam', type=float, default=5, help='kl_lambda')\n",
    "parser.add_argument('--epochs', type=int, default=60, help='number of epochs')\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7gTrxyDwX05"
   },
   "source": [
    "### Arquitetura do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cafe.model\n",
    "from cafe.model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lkEjrsCVwmUg"
   },
   "source": [
    "### Treinamento E Teste Codigos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, train_loader, optimizer, scheduler, device):\n",
    "  running_loss = 0.0\n",
    "  iter_cnt = 0\n",
    "  correct_sum = 0\n",
    "\n",
    "  model.to(device)\n",
    "  model.train()\n",
    "\n",
    "  total_loss = []\n",
    "  with tqdm(total=len(train_loader)) as pbar:\n",
    "      for batch_i, (imgs1, labels) in enumerate(train_loader):\n",
    "        imgs1 = imgs1.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "        output, MC_loss = model(imgs1, clip_model, labels, phase='train')\n",
    "\n",
    "        loss1 = nn.CrossEntropyLoss()(output, labels)\n",
    "\n",
    "        loss = loss1 + 5 * MC_loss[1] + 1.5 * MC_loss[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        iter_cnt += 1\n",
    "        _, predicts = torch.max(output, 1)\n",
    "        correct_num = torch.eq(predicts, labels).sum()\n",
    "        correct_sum += correct_num\n",
    "        running_loss += loss\n",
    "\n",
    "        pbar.update(1)  # Update progress bar for each batch\n",
    "\n",
    "  scheduler.step()\n",
    "  running_loss = running_loss / iter_cnt\n",
    "  acc = correct_sum.float() / float(train_loader.dataset.__len__())\n",
    "  return acc, running_loss\n",
    "\n",
    "setup_seed(3407)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        iter_cnt = 0\n",
    "        correct_sum = 0\n",
    "        data_num = 0\n",
    "\n",
    "\n",
    "        for batch_i, (imgs1, labels) in enumerate(test_loader):\n",
    "            imgs1 = imgs1.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "\n",
    "            outputs, _ = model(imgs1, clip_model, labels, phase='test')\n",
    "\n",
    "\n",
    "            loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "\n",
    "            iter_cnt += 1\n",
    "            _, predicts = torch.max(outputs, 1)\n",
    "\n",
    "            correct_num = torch.eq(predicts, labels).sum()\n",
    "            correct_sum += correct_num\n",
    "\n",
    "            running_loss += loss\n",
    "            data_num += outputs.size(0)\n",
    "\n",
    "        running_loss = running_loss / iter_cnt\n",
    "        test_acc = correct_sum.float() / float(data_num)\n",
    "        \n",
    "    return test_acc, running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_weights(model, checkpoint):\n",
    "    import collections\n",
    "    if 'state_dict' in checkpoint:\n",
    "        state_dict = checkpoint['state_dict']\n",
    "    else:\n",
    "        state_dict = checkpoint\n",
    "    model_dict = model.state_dict()\n",
    "    new_state_dict = collections.OrderedDict()\n",
    "    matched_layers, discarded_layers = [], []\n",
    "    for k, v in state_dict.items():\n",
    "        # If the pretrained state_dict was saved as nn.DataParallel,\n",
    "        # keys would contain \"module.\", which should be ignored.\n",
    "        if k.startswith('module.'):\n",
    "            k = k[7:]\n",
    "        if k in model_dict and model_dict[k].size() == v.size():\n",
    "            new_state_dict[k] = v\n",
    "            matched_layers.append(k)\n",
    "        else:\n",
    "            discarded_layers.append(k)\n",
    "    # new_state_dict.requires_grad = False\n",
    "    model_dict.update(new_state_dict)\n",
    "\n",
    "    model.load_state_dict(model_dict)\n",
    "    print('load_weight', len(matched_layers))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight : torch.Size([7, 512])\n",
      "bias : torch.Size([7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (features2): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Caminho do modelo em relação ao diretório atual (onde está o notebook)\n",
    "model_path = os.path.join(os.path.dirname(os.getcwd()), 'models', 'resnet18_msceleb.pth')\n",
    "\n",
    "# Carregando o modelo\n",
    "model = Model(model_path=model_path)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0002, weight_decay=0.0001)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_transforms = transforms.Compose([\n",
    "    #transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    #transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomErasing(scale=(0.02, 0.25))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Caregamento de Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diretório '/home/sergiojunior/FER-generalizavel/models/cafe' garantido (criado se não existia).\n"
     ]
    }
   ],
   "source": [
    "save_path = os.path.join(os.path.dirname(os.getcwd()), 'models/cafe')\n",
    "# os.makedirs() com exist_ok=True é a forma mais concisa\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "print(f\"Diretório '{save_path}' garantido (criado se não existia).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YblEzXiawbnA"
   },
   "source": [
    "# Teste cruzado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download de datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.12).\n",
      "Path to dataset files: /home/sergiojunior/.cache/kagglehub/datasets/shuvoalok/raf-db-dataset/versions/2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path_rafdb = kagglehub.dataset_download(\"shuvoalok/raf-db-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path_rafdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.12).\n",
      "Path to dataset files: /home/sergiojunior/.cache/kagglehub/datasets/arnabkumarroy02/ferplus/versions/3\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path_fer = kagglehub.dataset_download(\"arnabkumarroy02/ferplus\")\n",
    "\n",
    "print(\"Path to dataset files:\", path_fer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.12).\n",
      "Path to dataset files: /home/sergiojunior/.cache/kagglehub/datasets/mahmoudima/mma-facial-expression/versions/1/MMAFEDB\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path_mma = kagglehub.dataset_download(\"mahmoudima/mma-facial-expression\")\n",
    "path_mma = path_mma + '/MMAFEDB'\n",
    "print(\"Path to dataset files:\", path_mma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Teste entre dominios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aux.emotion_idx import *\n",
    "from emotion_datasets import MMADataset, FERPlusDataset, RafDataSet, SFEWDataset, AffectNetDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_affectnet_root = '/workspace/sergiojunior/AffectNet-8Labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregado 3500 itens do val_set.\n",
      "3093\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "dataset_sfew = SFEWDataset(root_dir=path_sfew, idx_test=emotion_to_index_raf, idx_sfew=index_to_emotion_sfew, split=\"Val\", transform=eval_transforms)\n",
    "loader_sfew = torch.utils.data.DataLoader(dataset_sfew, batch_size=args.batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=args.workers,\n",
    "                                          pin_memory=True)\n",
    "\"\"\"\n",
    "\n",
    "dataset_mma = MMADataset(root_dir=path_mma, idx_test=emotion_to_index_raf, idx_mma=index_to_emotion_mma, split=\"test\", transform=eval_transforms)\n",
    "loader_mma = torch.utils.data.DataLoader(dataset_mma, batch_size=args.batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=args.workers,\n",
    "                                          pin_memory=True)\n",
    "\n",
    "dataset_affect = AffectNetDataset(root_dir=temp_affectnet_root, idxs_test=emotion_to_index_raf, idxs_aff=index_to_emotion_aff, subset='val', transform=eval_transforms)\n",
    "loader_affect = torch.utils.data.DataLoader(dataset_affect, batch_size=args.batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=args.workers,\n",
    "                                          pin_memory=True)\n",
    "\n",
    "dataset_raf = RafDataSet(path_rafdb, idxs_test=emotion_to_index_raf, idxs_raf=index_to_emotion_raf, train=False, transform=eval_transforms)\n",
    "loader_raf = torch.utils.data.DataLoader(dataset_raf,\n",
    "                                           batch_size=args.batch_size,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=args.workers,\n",
    "                                           pin_memory=True)\n",
    "\n",
    "dataset_fer = FERPlusDataset(root_dir=path_fer, idxs_test=emotion_to_index_raf, idxs_fer=index_to_emotion_fer, subset=\"test\", transform=eval_transforms)\n",
    "loader_fer = torch.utils.data.DataLoader(dataset_fer, batch_size=args.batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=args.workers,\n",
    "                                          pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_weight 122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-62-9fc62cc829c2>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(f\"{save_path}/ours_best_RAFDB.pth\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (features2): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(f\"{save_path}/ours_best_RAFDB.pth\")\n",
    "checkpoint = checkpoint[\"model_state_dict\"]\n",
    "model = load_pretrained_weights(model, checkpoint)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loader_sfew' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m###### SFEW\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m acc_raf_sfew, test_loss \u001b[38;5;241m=\u001b[39m test(model, \u001b[43mloader_sfew\u001b[49m, device)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest acc dbtrain-raf dbtest-sfew: \u001b[39m\u001b[38;5;124m'\u001b[39m, acc_raf_sfew)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loader_sfew' is not defined"
     ]
    }
   ],
   "source": [
    "###### SFEW\n",
    "acc_raf_sfew, test_loss = test(model, loader_sfew, device)\n",
    "print('test acc dbtrain-raf dbtest-sfew: ', acc_raf_sfew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc dbtrain-raf dbtest-affect:  tensor(0.4740, device='cuda:0')\n",
      "test acc dbtrain-raf dbtest-raf:  tensor(0.8941, device='cuda:0')\n",
      "test acc dbtrain-raf dbtest-fer:  tensor(0.6214, device='cuda:0')\n",
      "test acc dbtrain-raf dbtest-mma:  tensor(0.5554, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###### AFFECT\n",
    "acc_raf_affect, test_loss = test(model, loader_affect, device)\n",
    "print('test acc dbtrain-raf dbtest-affect: ', acc_raf_affect)\n",
    "\n",
    "### RAFDB\n",
    "acc_raf_raf, test_loss = test(model, loader_raf, device)\n",
    "print('test acc dbtrain-raf dbtest-raf: ', acc_raf_raf)\n",
    "\n",
    "###### FER\n",
    "acc_raf_fer, test_loss = test(model, loader_fer, device)\n",
    "print('test acc dbtrain-raf dbtest-fer: ', acc_raf_fer)\n",
    "\n",
    "###### MMA\n",
    "acc_raf_mma, test_loss = test(model, loader_mma, device)\n",
    "print('test acc dbtrain-raf dbtest-mma: ', acc_raf_mma)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 696331,
     "sourceId": 1218456,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1780823,
     "sourceId": 2905596,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2784784,
     "sourceId": 4876418,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5369417,
     "sourceId": 8926506,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5954662,
     "sourceId": 9730490,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6477402,
     "sourceId": 10462385,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6478017,
     "sourceId": 10463310,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
